{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94a231f9",
   "metadata": {},
   "source": [
    "### Sleep simulations\n",
    "\n",
    "#### Installation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20a1c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy==1.24.2\n",
    "!pip tensorflow-macos==2.11.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12409883",
   "metadata": {},
   "source": [
    "#### Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c95a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sleep_utils import *\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8424d28",
   "metadata": {},
   "source": [
    "#### Train initial VAEs\n",
    "\n",
    "Train initial VAEs to avoid repeating this each time (leave commented out to use the VAE weights provided):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d72273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seeds = range(0, 1)\n",
    "# train_with_schedule_multiple_seeds(seeds, \n",
    "#                        num_cycles=10, \n",
    "#                        start_fraction_rem=0, \n",
    "#                        end_fraction_rem=0,\n",
    "#                        inverted=True,\n",
    "#                        use_initial_weights=False)\n",
    "\n",
    "# !mv decoder.h5 decoder_inv.h5\n",
    "# !mv encoder.h5 encoder_inv.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b0495f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# seeds = range(0, 1)\n",
    "# train_with_schedule_multiple_seeds(seeds, \n",
    "#                        num_cycles=10, \n",
    "#                        start_fraction_rem=0, \n",
    "#                        end_fraction_rem=0,\n",
    "#                        inverted=False,\n",
    "#                        use_initial_weights=False)\n",
    "\n",
    "# !mv decoder.h5 decoder_non_inv.h5\n",
    "# !mv encoder.h5 encoder_non_inv.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24698277-33e2-42ab-9aa1-bc0877d8dc3d",
   "metadata": {},
   "source": [
    "#### Baselines without sleep phase alternation\n",
    "\n",
    "Before modelling how differing schedules of REM / NREM sleep stages affect learning, let's just test whether generative replay helps avoid catastrophic forgeting of representations.\n",
    "\n",
    "The shuffled_baselines() function below can be used to do this. With baseline_type='new' only the new memories are used to train the VAE. With baseline_type='old' only self-generated memories (i.e. samples from the existing VAE) are used to train the VAE. With baseline_type='both' both of the above are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3407f21-9416-429d-9766-7fa3c16b123a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffled_baselines(baseline_type='both',\n",
    "                       use_initial_weights=True, \n",
    "                       latent_dim=5, \n",
    "                       seed=0, \n",
    "                       inverted=True, \n",
    "                       lr=0.001,\n",
    "                       num=1000,\n",
    "                       continue_training=True):\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    if inverted is True:\n",
    "        mnist_train, mnist_test, fmnist_train, fmnist_test = prepare_datasets(split_by_digits=False, \n",
    "                                                                              split_by_inversion=True)\n",
    "    else:\n",
    "        mnist_train, mnist_test, fmnist_train, fmnist_test = prepare_datasets(split_by_digits=True, \n",
    "                                                                              split_by_inversion=False)\n",
    "\n",
    "    if use_initial_weights is False:\n",
    "        vae = train_mnist_vae(mnist_train, 'mnist', generative_epochs=25, learning_rate=0.001, latent_dim=latent_dim)\n",
    "    else:\n",
    "        print(\"Starting with saved weights:\")\n",
    "\n",
    "    encoder, decoder = models_dict['mnist'](latent_dim=latent_dim)\n",
    "    vae = VAE(encoder, decoder, kl_weighting=1)\n",
    "    if inverted is True:\n",
    "        vae.encoder.load_weights(\"encoder_inv.h5\")\n",
    "        vae.decoder.load_weights(\"decoder_inv.h5\")\n",
    "    if inverted is False:\n",
    "        vae.encoder.load_weights(\"encoder_non_inv.h5\")\n",
    "        vae.decoder.load_weights(\"decoder_non_inv.h5\")\n",
    "    opt = keras.optimizers.Adam(learning_rate=lr, jit_compile=False)\n",
    "    vae.compile(optimizer=opt)\n",
    "    \n",
    "    m_err, f_err = plot_error_dists(vae, mnist_test, fmnist_test)\n",
    "    check_generative_recall(vae, mnist_test, noise_level=0.0)\n",
    "    \n",
    "    sampled_digits = [sample_item(vae, latent_dim=latent_dim) for i in range(100)]\n",
    "    sampled_digits = np.array(sampled_digits)\n",
    "    show_samples(sampled_digits)\n",
    "    \n",
    "    mnist_errors = []\n",
    "    fmnist_errors = []\n",
    "    \n",
    "    mnist_errors.append(np.mean(m_err))\n",
    "    fmnist_errors.append(np.mean(f_err))\n",
    "\n",
    "    random_indices = np.random.choice(fmnist_train.shape[0], num, replace=False)\n",
    "    fmnist_subset = fmnist_train[random_indices]\n",
    "    sampled_digits = [sample_item(vae, latent_dim=latent_dim) for i in range(num)]\n",
    "\n",
    "    if baseline_type == 'new':\n",
    "        train_data = fmnist_subset\n",
    "    if baseline_type == 'old':\n",
    "        train_data = np.array(sampled_digits)\n",
    "    if baseline_type == 'both':\n",
    "        train_data = sampled_digits + list(fmnist_subset)\n",
    "        shuffle(train_data)\n",
    "        train_data = np.array(train_data[0:num])\n",
    "    \n",
    "    print(\"Show training samples:\")\n",
    "    show_samples(train_data)\n",
    "                           \n",
    "    vae.fit(train_data, epochs=10, verbose=0, batch_size=1, shuffle=True)\n",
    "    \n",
    "    # test reconstruction error of mnist_test and fmnist_test\n",
    "    m_err, f_err = plot_error_dists(vae, mnist_test, fmnist_test)\n",
    "    mnist_errors.append(np.mean(m_err))\n",
    "    fmnist_errors.append(np.mean(f_err))\n",
    "\n",
    "    check_generative_recall(vae, mnist_test, noise_level=0.0)\n",
    "    check_generative_recall(vae, fmnist_test, noise_level=0.0)\n",
    "    \n",
    "    return mnist_errors, fmnist_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfff54f-28fe-470c-a0bf-3ce2987a008b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shuffled_baselines(baseline_type='new', inverted=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a8df82-1230-48d7-8733-95423e3af4cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shuffled_baselines(baseline_type='old', inverted=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d11fa0a-f84c-4a1e-b5b4-bf681fe9f1d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shuffled_baselines(baseline_type='both', inverted=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087da360",
   "metadata": {},
   "source": [
    "#### Try different schedules\n",
    "\n",
    "For example, here we vary just the number of cycles (for a fixed total number of epochs of training)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fca85d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rem_fraction_pairs = [(0.5,0.5), (0,0), (1,1)]\n",
    "cycles_values = [50,20,10,5]\n",
    "lrs = [0.001]\n",
    "\n",
    "seeds = range(0, 3)\n",
    "\n",
    "for lr in lrs:\n",
    "    for num_cycles in cycles_values:\n",
    "        for (start_fraction_rem, end_fraction_rem) in rem_fraction_pairs:\n",
    "            train_with_schedule_multiple_seeds(seeds, \n",
    "                                               total_eps=50,\n",
    "                                               num_cycles=25, \n",
    "                                               start_fraction_rem=start_fraction_rem, \n",
    "                                               end_fraction_rem=end_fraction_rem,\n",
    "                                               inverted=True,\n",
    "                                               lr=lr,\n",
    "                                               num=5,\n",
    "                                               continue_training=True)\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
