{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94a231f9",
   "metadata": {},
   "source": [
    "### Sleep simulations\n",
    "\n",
    "#### Installation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20a1c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy==1.24.2\n",
    "!pip tensorflow-macos==2.11.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12409883",
   "metadata": {},
   "source": [
    "#### Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c95a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sleep_utils import *\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24698277-33e2-42ab-9aa1-bc0877d8dc3d",
   "metadata": {},
   "source": [
    "#### Baselines without sleep phase alternation\n",
    "\n",
    "Before modelling how differing schedules of REM / NREM sleep stages affect learning, let's just test whether generative replay helps avoid catastrophic forgeting of representations.\n",
    "\n",
    "The shuffled_baselines() function below can be used to do this. With baseline_type='new' only the new memories are used to train the VAE. With baseline_type='old' only self-generated memories (i.e. samples from the existing VAE) are used to train the VAE. With baseline_type='both' both of the above are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3407f21-9416-429d-9766-7fa3c16b123a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffled_baselines(baseline_type='both',\n",
    "                       use_initial_weights=True, \n",
    "                       latent_dim=20, \n",
    "                       seed=0, \n",
    "                       inverted=True, \n",
    "                       lr=0.001,\n",
    "                       num_new=1000,\n",
    "                       num_sampled=1000,\n",
    "                       continue_training=True):\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    if inverted is True:\n",
    "        mnist_train, mnist_test, fmnist_train, fmnist_test = prepare_datasets(split_by_digits=False, \n",
    "                                                                              split_by_inversion=True)\n",
    "    else:\n",
    "        mnist_train, mnist_test, fmnist_train, fmnist_test = prepare_datasets(split_by_digits=True, \n",
    "                                                                              split_by_inversion=False)\n",
    "\n",
    "    if use_initial_weights is False:\n",
    "        vae = train_mnist_vae(mnist_train, 'mnist', generative_epochs=25, learning_rate=0.001, latent_dim=latent_dim)\n",
    "        if inverted is True:\n",
    "            !mv decoder.h5 decoder_inv.h5\n",
    "            !mv encoder.h5 encoder_inv.h5\n",
    "        else:\n",
    "            !mv decoder.h5 decoder_non_inv.h5\n",
    "            !mv encoder.h5 encoder_non_inv.h5\n",
    "    else:\n",
    "        print(\"Starting with saved weights:\")\n",
    "\n",
    "    encoder, decoder = models_dict['mnist'](latent_dim=latent_dim)\n",
    "    vae = VAE(encoder, decoder, kl_weighting=1)\n",
    "    if inverted is True:\n",
    "        vae.encoder.load_weights(\"encoder_inv.h5\")\n",
    "        vae.decoder.load_weights(\"decoder_inv.h5\")\n",
    "    if inverted is False:\n",
    "        vae.encoder.load_weights(\"encoder_non_inv.h5\")\n",
    "        vae.decoder.load_weights(\"decoder_non_inv.h5\")\n",
    "    opt = keras.optimizers.Adam(learning_rate=lr, jit_compile=False)\n",
    "    vae.compile(optimizer=opt)\n",
    "    \n",
    "    m_err, f_err = plot_error_dists(vae, mnist_test, fmnist_test)\n",
    "    if inverted is True:\n",
    "        m_err, f_err = plot_error_dists(vae, mnist_test, fmnist_test, f'{baseline_type}_before', 'MNIST', 'Inverted MNIST')\n",
    "    else:\n",
    "        m_err, f_err = plot_error_dists(vae, mnist_test, fmnist_test, f'{baseline_type}_before', 'MNIST 0-4', 'MNIST 5-9')\n",
    "    check_generative_recall(vae, mnist_test, noise_level=0.0)\n",
    "    \n",
    "    sampled_digits = [sample_item(vae, latent_dim=latent_dim) for i in range(100)]\n",
    "    sampled_digits = np.array(sampled_digits)\n",
    "    show_samples(sampled_digits)\n",
    "    \n",
    "    mnist_errors = []\n",
    "    fmnist_errors = []\n",
    "    \n",
    "    mnist_errors.append(np.mean(m_err))\n",
    "    fmnist_errors.append(np.mean(f_err))\n",
    "\n",
    "    random_indices = np.random.choice(fmnist_train.shape[0], num_new, replace=False)\n",
    "    fmnist_subset = fmnist_train[random_indices]\n",
    "    sampled_digits = [sample_item(vae, latent_dim=latent_dim) for i in range(num_sampled)]\n",
    "\n",
    "    if baseline_type == 'new':\n",
    "        train_data = fmnist_subset\n",
    "    if baseline_type == 'old':\n",
    "        train_data = np.array(sampled_digits)\n",
    "    if baseline_type == 'both':\n",
    "        train_data = sampled_digits + list(fmnist_subset)\n",
    "        shuffle(train_data)\n",
    "        train_data = np.array(train_data)\n",
    "    \n",
    "    print(\"Show training samples:\")\n",
    "    show_samples(train_data)\n",
    "                           \n",
    "    vae.fit(train_data, epochs=20, verbose=0, batch_size=32, shuffle=True)\n",
    "    \n",
    "    if inverted is True:\n",
    "        m_err, f_err = plot_error_dists(vae, mnist_test, fmnist_test, f'{baseline_type}_{num_new}new_{num_sampled}sampled', 'MNIST', 'Inverted MNIST')\n",
    "    else:\n",
    "        m_err, f_err = plot_error_dists(vae, mnist_test, fmnist_test, f'{baseline_type}_{num_new}new_{num_sampled}sampled', 'MNIST 0-4', 'MNIST 5-9')\n",
    "    mnist_errors.append(np.mean(m_err))\n",
    "    fmnist_errors.append(np.mean(f_err))\n",
    "\n",
    "    check_generative_recall(vae, mnist_test, noise_level=0.0)\n",
    "    check_generative_recall(vae, fmnist_test, noise_level=0.0)\n",
    "    \n",
    "    return mnist_errors, fmnist_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfff54f-28fe-470c-a0bf-3ce2987a008b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shuffled_baselines(baseline_type='new', inverted=True, use_initial_weights=True)\n",
    "shuffled_baselines(baseline_type='old', inverted=True)\n",
    "shuffled_baselines(baseline_type='both', inverted=True, num_new=500, num_sampled=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62f3fd3-914d-4d11-b1f5-97831354e6af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shuffled_baselines(baseline_type='new', inverted=False, use_initial_weights=True)\n",
    "shuffled_baselines(baseline_type='old', inverted=False)\n",
    "shuffled_baselines(baseline_type='both', inverted=False, num_new=500, num_sampled=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcb597a-4262-4f72-ac8b-f91bb7325cbd",
   "metadata": {},
   "source": [
    "Vary the number of samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801a0c22-20a3-45d2-86e5-d476cb5c04d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_mnist_errors = {}\n",
    "all_fmnist_errors = {}\n",
    "\n",
    "for num_sampled in [0,10,20,25,30,35,40,50,60]:\n",
    "    all_mnist_errors[num_sampled] = []\n",
    "    all_fmnist_errors[num_sampled] = []\n",
    "    for trial in range(3):\n",
    "        mnist_errors, fmnist_errors = shuffled_baselines(baseline_type='both', \n",
    "                                                         inverted=True, \n",
    "                                                         num_new=500, \n",
    "                                                         num_sampled=num_sampled)\n",
    "        all_mnist_errors[num_sampled].append(mnist_errors)\n",
    "        all_fmnist_errors[num_sampled].append(fmnist_errors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7758273-5dd8-4f28-b2b1-af8cce36bc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sizes = sorted(all_mnist_errors.keys())\n",
    "\n",
    "mnist_means = [np.mean([x[1] for x in all_mnist_errors[s]]) for s in sample_sizes]\n",
    "mnist_sems = [np.std([x[1] for x in all_mnist_errors[s]]) / np.sqrt(len([x[1] for x in all_mnist_errors[s]])) for s in sample_sizes]\n",
    "\n",
    "fmnist_means = [np.mean([x[1] for x in all_fmnist_errors[s]]) for s in sample_sizes]\n",
    "fmnist_sems = [np.std([x[1] for x in all_fmnist_errors[s]]) / np.sqrt(len([x[1] for x in all_mnist_errors[s]])) for s in sample_sizes]\n",
    "\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.plot(sample_sizes, mnist_means, label='MNIST', color='black', marker='o', alpha=0.5)\n",
    "plt.plot(sample_sizes, fmnist_means, label='Inverted MNIST', color='blue', marker='o', alpha=0.5)\n",
    "\n",
    "plt.xlabel('Number of self-generated samples')\n",
    "plt.ylabel('Mean reconstruction error')\n",
    "plt.xticks(range(0,60,10))\n",
    "plt.legend()\n",
    "plt.savefig('number_of_samples.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8424d28",
   "metadata": {},
   "source": [
    "#### Train initial VAEs\n",
    "\n",
    "Train initial VAEs to avoid repeating this each time (leave commented out to use the VAE weights provided):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af17f13-564f-4b8b-9b1f-9e52d261eb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seeds = range(0, 1)\n",
    "# train_with_schedule_multiple_seeds(seeds, \n",
    "#                        num_cycles=10, \n",
    "#                        start_fraction_rem=0, \n",
    "#                        end_fraction_rem=0,\n",
    "#                        inverted=True,\n",
    "#                        use_initial_weights=False)\n",
    "\n",
    "# !mv decoder.h5 decoder_inv.h5\n",
    "# !mv encoder.h5 encoder_inv.h5\n",
    "\n",
    "# seeds = range(0, 1)\n",
    "# train_with_schedule_multiple_seeds(seeds, \n",
    "#                        num_cycles=10, \n",
    "#                        start_fraction_rem=0, \n",
    "#                        end_fraction_rem=0,\n",
    "#                        inverted=False,\n",
    "#                        use_initial_weights=False)\n",
    "\n",
    "# !mv decoder.h5 decoder_non_inv.h5\n",
    "# !mv encoder.h5 encoder_non_inv.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087da360",
   "metadata": {},
   "source": [
    "#### Try different schedules\n",
    "\n",
    "For example, here we vary just the number of cycles (for a fixed total number of epochs of training)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fca85d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rem_fraction_pairs = [(0.5,0.5), (0,0), (1,1)]\n",
    "cycles_values = [50,20,10,5]\n",
    "lrs = [0.001]\n",
    "\n",
    "seeds = range(0, 3)\n",
    "\n",
    "for lr in lrs:\n",
    "    for num_cycles in cycles_values:\n",
    "        for (start_fraction_rem, end_fraction_rem) in rem_fraction_pairs:\n",
    "            train_with_schedule_multiple_seeds(seeds, \n",
    "                                               total_eps=50,\n",
    "                                               num_cycles=25, \n",
    "                                               start_fraction_rem=start_fraction_rem, \n",
    "                                               end_fraction_rem=end_fraction_rem,\n",
    "                                               inverted=True,\n",
    "                                               lr=lr,\n",
    "                                               num=5,\n",
    "                                               continue_training=True)\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
